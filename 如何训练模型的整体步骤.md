#视觉识别 #卷积神经网络


相关关键技术
- [实战解析：利用预训练模型加速新模型训练之路](https://cloud.baidu.com/article/3336258)
- [【科普】大模型量化技术大揭秘：INT4、INT8、FP32、FP16的差异与应用解析 - 大模型知识库|大模型训练|开箱即用的企业大模型应用平台|智能体开发|53AI](https://www.53ai.com/news/LargeLanguageModel/2024071736920.html#:~:text=%E7%9A%84%E5%85%BC%E5%AE%B9%E6%80%A7%E3%80%82-,INT8%E9%87%8F%E5%8C%96,%E5%AD%98%E5%82%A8%E5%92%8C%E8%AE%A1%E7%AE%97%E7%9A%84%E9%9C%80%E6%B1%82%E3%80%82)
- [AI模型优化深度解析剪枝量化蒸馏](https://cloud.baidu.com/article/3368694)
- [YOLO 性能指标 -Ultralytics YOLO 文档](https://docs.ultralytics.com/zh/guides/yolo-performance-metrics/)

### 制作训练数据

![[Pasted image 20241224093957.png|500x300]]


1. 先有两个文件夹 images ,lables 
2. images中存放图片，labels中存放描述文件cat_dog.txt,其中按照算法进行计算box中心点，以及box宽，高
   x_center = (box_x_left+box_x_width/2)/image_width  
	y_center = (box_y_top+box_height/2)/image_height  
	width = box_width/image_width  
	height = box_height/image_height
3. 训练数据集位于“train”文件夹中，验证数据集位于“val”文件夹中
4. 创建一个数据集描述符 YAML 文件，该文件指向已创建的数据集并描述其中的对象类
5. 该 YAML 文件应传递给`train`模型的方法来启动训练过程

**用于注释机器学习的图像的软件** ,参考[Roboflow Annotate: Label Images Faster Than Ever](https://roboflow.com/annotate)


![[Pasted image 20241220105555.png]]

![[Pasted image 20241220105603.png]] 
在label中cat_dog.txt中的描述




![[Pasted image 20241220105537.png]]

训练数据集位于“train”文件夹中，验证数据集位于“val”文件夹中



最后，您需要创建一个数据集描述符 YAML 文件，该文件指向已创建的数据集并描述其中的对象类

![[Pasted image 20241220105745.png]]
在前两行中，您需要指定训练和验证数据集的图像路径。路径可以是相对于当前文件夹的路径，也可以是绝对路径。然后，该`nc`行指定这些数据集中存在的类数，并且是按**正确顺序排列的类名数组**。这些项目的索引是您在注释图像时使用的数字，当使用该方法检测对象时，模型将返回这些索引。因此，如果您对猫使用“0”，那么它应该是数组中的第一个项目。 


### 训练YOLOv8模型

数据准备好后，您需要将其传递给模型
```python
model.train(data="data.yaml", epochs=30)
```

循环训练30次（默认为 100），[其他选项](https://docs.ultralytics.com/zh/modes/train/#arguments)

每个训练周期包含两个阶段：**训练阶段**和**验证阶段**。

#### 训练阶段
- 从训练数据集中提取随机一批图像（可以使用选项指定批次中的图像数量`batch`）。
- 将这些图像传递给模型并接收所有检测到的对象及其类别的结果边界框。
- 将结果传递给损失函数，该函数用于将接收到的输出与这些图像的注释文件中的正确结果进行比较。损失函数计算错误量。
- 损失函数的结果传递给`optimizer`根据正确方向上的误差量调整模型权重，以减少下一轮的误差。默认情况下，使用[SGD（随机梯度下降）](https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31)优化器，但您可以尝试其他优化器，如[Adam](https://www.linkedin.com/pulse/understanding-adam-optimizer-gradient-descent-evan-dunbar/) ，以查看差异。
#### 验证阶段
- 从验证数据集中提取图像。
- 将它们传递给模型并接收这些图像的检测到的边界框。
- 将接收到的结果与来自注释文本文件的这些图像的真实值进行比较。
- 根据实际结果和预期结果之间的差异计算模型的精度。

屏幕上显示每个时期每个阶段的进度和结果。这样，您就可以看到模型如何从一个时期到另一个时期进行学习和改进。

当你运行`train`代码时，你将在训练循环中看到类似的输出：
![[Pasted image 20241220112254.png]]

对于每个时期，它显示训练和验证阶段的摘要：第 1 行和第 2 行显示训练阶段的结果，第 3 行和第 4 行显示每个时期验证阶段的结果。

训练阶段包括计算损失函数中的误差量，因此这里最有价值的指标是 `box_loss`和`cls_loss`。

- `box_loss`显示检测到的边界框的错误量。
- `cls_loss`显示检测到的对象类别的错误量。

为什么损失会分成几个指标？因为模型可以正确检测物体周围的边界框，但错误地检测此框中的物体类别。例如，在我的实践中，它将狗检测为马，但正确检测到了物体的尺寸。

如果模型确实从数据中学到一些东西，那么你应该看到这些值随着时间推移而减少。在上一个截图中，`box_loss`减少的值为：0.7751、0.7473、0.742，`cls_loss`减少的值为：0.702、0.6422、0.6211。

在验证阶段，它使用验证数据集中的图像计算训练后的模型质量。最有价值的质量指标是 mAP50-95，即[平均精度](https://www.v7labs.com/blog/mean-average-precision)。如果模型学习并改进，精度应该会随着时间的流逝而增长。在上一个截图中，它缓慢增长：0.788、0.788、0.791。

如果在最后一个 epoch 之后你没有获得可接受的精度，你**可以增加 epoch 的数量并再次运行训练**。此外，你**可以调整其他参数`batch`，如`lr0`，`lrf`或更改使用的`optimizer`**。这里没有明确的规则该怎么做，但有很多建议可以写一本书。但简而言之，==需要进行实验并比较结果==。

除了这些指标之外，它`train`在工作期间还会在磁盘上写入大量统计数据。训练开始时，它会`runs/detect/train`在当前文件夹中创建子文件夹，并且在每个周期之后都会将不同的日志文件记录到其中。

此外，它会将每个时期后训练好的模型导出到`/runs/detect/train/weights/last.pt`文件中，并将精度最高的模型导出到==`/runs/detect/train/weights/best.pt`==文件中。因此，训练完成后，您可以获取该`best.pt`文件以用于生产。


常见报错
![[Pasted image 20241220133446.png]]
1. 尝试安装pytorch ```
```python
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 

pip3 install torch torchvision torchaudio   不支持CUDA版本

```

```python
import os 
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"  #尝试使用CPU而不是GPU
```



